\documentclass[12pt]{article}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{fullpage}
\usepackage{commath}
\usepackage{graphicx}
\usepackage{pdfcomment}
%\usepackage{coffee4}
\usepackage{lipsum}
\usepackage{showkeys}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{verbatim}
\usepackage{longtable}

%General Shorthand Macros
\newcommand{\skipLine}{\vspace{12pt}}
\newcommand{\mb}{\mathbb}
\newcommand{\mc}{\mathcal}
\newcommand{\ms}{\mathscr}
\newcommand{\ra}{\rightarrow}
\newcommand{\ov}{\overline}
\newcommand{\os}{\overset}
\newcommand{\un}{\underline}
\newcommand{\te}{\text}
\newcommand{\ep}{\epsilon}
\newcommand{\tr}{\textcolor{red}}
\newcommand{\tb}{\textcolor{blue}}
\newcommand{\tg}{\textcolor{green}}
\newcommand{\labe}[1]{\tr{\texttt{Label: #1}}}
\newcommand{\tbs}{\textbackslash}
\newcommand{\purpose}{\textbf{Purpose: }}
\newcommand{\pfsum}{\textbf{Proof Summary: }}
\newcommand{\usein}{\textbf{Used in: }}
\newcommand{\app}{\textbf{Applies: }}
\newcommand{\ind}{\hspace{24pt}}
\newcommand{\lin}{\rule{\linewidth}{0.4 pt}}
\newcommand{\pr}{\mb{P}}							%probability
\newcommand{\ex}[1]{\mb{E}\left[#1\right]}			%expectation
\newcommand{\exmu}[2]{\mb{E}^{#1}\left[#2\right]}	%exp wrt a measure
\newcommand{\deq}{\overset{\text{(d)}}{=}}			%equal in dist
\newcommand{\defeq}{:=}								%definition equal
\newcommand{\msr}{\mc{M}}							%space of measures
\newcommand{\pmsr}{\mc{P}}							%space of pmsrs
\newcommand{\cad}{\mb{D}}							%Cadlag space
\newcommand{\argmin}{\te{arg}\min}


%Notation and Basic Assumptions
%Graph Notation
%Base Commands
\newcommand{\sta}{\mc{X}}							%state space
\newcommand{\neigh}[1]{\partial_{#1}}				%neighborhood
\newcommand{\dneigh}[1]{\partial^2_{#1}}			%double neigh
\newcommand{\tneigh}[1]{\partial^3_{#1}}			%double neigh
\newcommand{\gneigh}[2]{\partial^{#1}_{#2}}			%neighborhood w G
\newcommand{\dgneigh}[2]{\partial^{2,#1}_{#2}}		%double neigh w G
\newcommand{\tgneigh}[2]{\partial^{3,#1}_{#2}}		%double neigh w G
\newcommand{\cl}[1]{\ov{#1}}						%graph closure
\renewcommand{\root}{\mathbf{0}}

%Modifiers
\newcommand{\stb}[1]{_{#1}}							%add base of \st
\newcommand{\indx}[1]{^{#1}}						%sublimit index
\newcommand{\subg}[1]{_{#1}}						%subgraph


%Process Notation
%Base Commands
\newcommand{\Xf}{X}									%Full process
\newcommand{\poiss}{N}								%Poisson process
\newcommand{\leb}{\lambda}							%Lebesgue msr
\newcommand{\Sm}{\ell}								%ctng msr on sta
\newcommand{\rate}{r}								%jump rate
\newcommand{\F}{\mc{F}}								%filtrations
\newcommand{\m}{\mu}								%law of \Xf
\newcommand{\proj}{\pi}								%projection

%Modifiers
\newcommand{\poissv}[1]{_{#1}}						%v comp of Poisson
\newcommand{\poisso}[1]{^{#1}}						%Other P modifier
\newcommand{\vind}[1]{_{#1}}						%v component
\newcommand{\tme}[1]{(#1)}							%time
\newcommand{\tmi}[1]{#1}							%time interval
\newcommand{\gind}[1]{^{#1}}						%interaction net
\newcommand{\vpara}[1]{^{#1}}						%vertex param
\newcommand{\stpara}[1]{_{#1}}						%state parameter	
\newcommand{\tpara}[1]{_{#1}}						%time parameter
\newcommand{\gvpara}[2]{^{#1,#2}}					%G and v params
\newcommand{\psf}{_*}								%push forward
\newcommand{\tparapsf}[1]{_{#1,*}}					%psf t param


%Simultaneous Jumps
\newcommand{\Jmps}{\mc{J}}							%set of jumps


%Assumptions
\newcommand{\psize}{\ell}							%Branching size


%Well-Posedness
%Base Commands

%Modifiers
\newcommand{\trnc}[1]{_{#1}}						%Truncated graph


%Conditional Independence
%Base Commands
%Modifiers


%Statement
%Base Commands
\newcommand{\Xg}{Y}									%Alt proc rep
\newcommand{\brate}{\alt{\rate}}					%local rt at bdry

%Modifications
\newcommand{\inte}[1]{{#1}^\mathrm{o}}				%interior
\newcommand{\alt}[1]{\tilde{#1}}					%alternate



%Existence
%Base commands
\newcommand{\pmap}{\Lambda}							%Mk chain to PP
\newcommand{\rt}{\tau}								%PP time
\renewcommand{\mark}{\kappa}						%PP mark
\newcommand{\ratee}{\Gamma}							%generic rate
\newcommand{\cratee}{\alt{\ratee}}					%gen cdtl rate
\newcommand{\rp}{P}									%generic PP
\newcommand{\mm}{\nu}								%gen msr
\newcommand{\law}{\te{Law}}							%law
\newcommand{\ev}[1]{\ep^{#1}}						%std basis


%Uniqueness
%Base Commands
\newcommand{\Xh}{Z}									%2nd alt proc
\newcommand{\crate}{\hat{\rate}}					%dneigh bdry rate
\newcommand{\bgrate}{\ov{\rate}}					%gen bdry rate
\newcommand{\bcrate}{\hat{\brate}}					%neigh bdry rate
\newcommand{\mmm}{\eta}								%std msr

%Modifications
\newcommand{\gvjpara}[3]{^{#1,#2,#3}}				%include branch
\newcommand{\pup}









%reassign later
\newcommand{\arr}{\lambda}							%arrival rate
\newcommand{\neighI}[1]{\partial^I_{#1}}			%int. neigh
\newcommand{\IG}{\mc{L}}							%infinitesimal gen
\newcommand{\para}[1]{^{#1}}
\newcommand{\inter}[1]{#1^I}
\newcommand{\uni}{m}
\renewcommand{\d}{D}


\newtheorem{thms}{Theorem}[section]
\newtheorem{conj}[thms]{Conjecture}
\newtheorem{prop}[thms]{Proposition}
\newtheorem{coro}[thms]{Corollary}
\newtheorem{lem}[thms]{Lemma}
%\newtheorem{sublem}{Sublemma}[lem]
\newtheorem{defn}[thms]{Definition}
\newtheorem{assu}[thms]{Assumption}

\setlength{\parindent}{0pt}

\begin{document}

\title{General Graph Topology Results (Working Title)}
\author{Ankan Ganguly}

\maketitle

Remark: This document uses the results from the derivation of the local approximation on trees. I will refer to this derivation as the main paper for now.

\skipLine

Remark: In this paper I mostly work with locally finite graphs. However, I proved all my results in the main paper for bounded degree graphs. I may need to strengthen the assumptions of this paper to bounded degree. However, since we are working with local convergence, all results that hold for locally finite graphs should extend to bounded degree graphs (the one possible exception would be well-posedness results).

\section{TODO}

\begin{itemize}
\item Split assumption \ref{a::admissible} into 2 assumptions. One on the nature of the underlying graph \(G\), and the other on the process \(\Xf\gind{G}\). Adjust references to assumptions accordingly.

\item Modify assumption \ref{a::pbasics} to include regularity of \(\rate\gvpara{G}{v}\stpara{i}\) with respect to time. Ideally, it should be left-continuous.

\item Revise assumption \ref{Ex::Eassu} and lemma \ref{Ex::leftmod} after proof of uniqueness is complete.

\item Make sure modifications made to \(\gneigh{G}{v}\) and \(dgneigh{G}{v}\) are properly placed in the paper.

\item Bad notation! I use \(i\) to indicate elements of \(\sta\) and to enumerate branches of \(A\).
\end{itemize}


\section{Notation and basic assumptions}
\label{not}

\subsection{Graph Notation}
\label{g::not}

We consider an interacting particle system for which each node takes values in the countable state-space \(\sta = \mb{Z}\). Our goal is to understand the local evolution of a network whose nodes take values in \(\sta\). Therefore, we represent the interaction network between nodes by a rooted graph \(G = (V,E,\root)\) in which \(\root \in V\) is the vertex representing the node whose local evolution is of interest to us. When looking at sequences of such processes on networks, we let \(G\indx{k} = (V\indx{k},E\indx{k},\root\indx{k})\) represent the network structure in the sublimit.

\ind Given a specific rooted graph \(G\) and any vertex set \(\root \in A \subseteq V\), define \(G\subg{A} \defeq (A,E\cap A^2,\root)\). This is the maximal subgraph of \(G\) restricted to the vertices in \(A\). For any \(v \in V\), let \(\neigh{v}\subseteq V\) be the neighbors of \(v\) in \(g\). Let \(\cl{v} = \{v\}\cup\neigh{v}\). We also define the double neighborhood given by, \(\dneigh{v} = \cl{\neigh{v}}\setminus \{v\}\). The triple neighborhood will be \(\cl{\dneigh{v}} \setminus \{v\}\). These notions also extend to vertex set. If \(A\subseteq V\), then \(\neigh{A} = \{v \in V\setminus A: \exists u \in A\te{ s.t. } (u,v) \in E\}\). \(\cl{A} = A\cup \neigh{A}\). \(\dneigh{A} = \cl{\neigh{A}}\setminus A\). Similarly, \(\tneigh{A} = \dneigh{A} \cup \cl{\dneigh{A}}\setminus A\). When the graph we are working on is not clear from context, I may use \(\gneigh{G}{A}\), \(\dgneigh{G}{A}\) and \(\tgneigh{G}{A}\) to denote the neighborhood, double neighborhood and triple neighborhood of \(A\) with respect to \(G\).

\subsection{Process Notation}
\label{p::not}

In this context, define the \(\sta^V\)-valued c\`adl\`ag process \(\Xf\). For any \(v \in V\) and \(t < \infty\), let \(\Xf\vind{v}\tme{t}\) be the value the \(v\)-component of \(\Xf\) at time \(t\). Given a set \(A\subset V\) and an interval \(I \subset \mb{R}^+\), let \(\Xf\vind{A}\tmi{I}\) denote the path taken by the \(A\)-components of \(\Xf\) over \(\tmi{I}\). We denote the natural filtration of this process by \(\F\vpara{A}\tpara{t} \defeq \sigma \left(\Xf\vind{v}\tmi{[0,t]}\right)\). We will often be interested in the predictable sigma-algebra of the process given by \(\F\vpara{A}\tpara{t-} \defeq \bigvee_{s < t} \F\vpara{A}\tpara{s} = \sigma\left(\Xf\vind{v}\tmi{[0,t)}\right)\). Furthermore, when the evolution of \(\Xf\) with respect to its topology is clearly defined, but the specific interaction network of \(\Xf\) is not clear from context, we may write \(\Xf\gind{G}\) to represent the process \(\Xf\) with interaction network \(G\). Fix any \(v \in V,t \in \mb{R}^+\) and \(j \in \sta\setminus\{\Xf\vind{v}\tme{t}\}\). Then at time \(t\), we can define the jump rate \(\rate\gvpara{G}{v}\stpara{j}(G,t)\) to be the inverse of the expected time for \(\Xf\vind{v}\) to jump to \(\Xf\vind{v} + j\) time \(t\). It now becomes clear how we can define the interaction network. The interaction network is any graph \(G\) such that \(\Xf\) is a \(\sta^V\)-valued process and such that for every \(v \in V\),\(t\in \mb{R}^+\) and \(j \in \sta\), \(\rate\gvpara{G}{v}\stpara{j}(G,t)\) is \(\F\vpara{v}\tpara{t-}\)-measurable. 

\ind We can rigorously define this in the following manner. Let \(\Sm\) be the counting measure on \(\sta\). Let \(\leb\) be the Lebesgue measure on \(\mb{R}^2\). Let \(\{\poiss\poissv{v}:v \in V\}\) be a sequence of i.i.d. Poisson point processes on \(\sta\times \mb{R}^2\) with intensity \(\Sm\times \leb\). Let \(\Xf\tme{0}\) be an \(\sta^V\)-valued random variable. Let \(\Xf\tme{0}\) be some given \(\sta^V\)-valued random variable. Assume \(\rate\gvpara{G}{v}\stpara{j}(t)\) is \(\F\vpara{\cl{v}}\tpara{t-}\)-measurable for all \(v,j,t\) and that \(\rate\gvpara{G}{v}\stpara{j}:\mb{R}^+ \ra\mb{R}^+\) is an almost surely Borel-Measurable function. Consider the following SDE:

\begin{equation}
\Xf\gind{G}\vind{v}\tme{t} = \Xf\gind{G}\vind{v}\tme{0} + \int_{\sta}\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \rate\gvpara{G}{v}\stpara{i}(s)} \poiss\poissv{v}\left(dr,ds,di\right)
\label{p::Xf}
\end{equation}

Assuming equation \eqref{p::Xf} has a well-defined unique solution, this is the infinite-dimensional process whose marginals we are interested in.

\ind Let \(\m\) be the law of \(\Xf\). We are primarily interested in the marginals of \(\m\). For any \(A \subseteq V\), let \(\proj\vpara{A}(\Xf)\) map \(\Xf\) to an \(\sta^A\)-valued process defined by \((\proj\vpara{A}(\Xf))\vind{v} = \Xf\vind{v}\) for all \(v\in A\). Then the \(A\)-marginal of \(\m\) is given by the push-forward measure \(\proj\vpara{A}\psf(\m)\). I will often use the shorthand \(\m\vpara{A} \defeq \proj\psf\vpara{A}(\m)\). We may also be interested in restricting the process to some finite time interval \([0,T)\). In this case, we define \((\proj\vpara{A}\tpara{T}(\Xf))\vind{v}\tme{t} = \Xf\vind{v}\tme{t}\) for \(v \in A\) and \(t \in [0,T)\). The corresponding push-forward measure is given by \(\proj\vpara{A}\tparapsf{T}(\m)\). Again, I will use the shorthand \(\m\vpara{A}\tpara{T} \defeq \proj\vpara{A}\tparapsf{T}(\m)\). \(\m\tpara{0} = \law(\Xf\tme{0})\).

\subsubsection{Considering Simultaneous Jumps}
\label{sim::p}

The model described above is fairly general. However, it does not account for certain models such as the exclusion process in which multiple nodes of \(\Xf\) may update simultaneous with positive probability. This can be accounted for in the following manner. Let \(\Jmps \subseteq 2^V\) be the set of subsets of nodes of \(\Xf\) that can jump simultaneously with positive probability. We assume \(\Jmps\) is composed of finite sets. 

Let \tr{continue with this later. For now focus on the main argument. The idea here is to construct an interaction graph (kind of like I did for load-balancing earlier) which treats all simultaneous jumps as single nodes. Ideally this graph satisfies the conditions of general networks outlined later in the paper.}

\subsection{Assumptions}
\label{a::not}

The assumptions required for our results vary from extremely general to fairly restrictive.

\begin{assu}
\(G\) is a countable, connected, locally finite rooted graph.
\label{a::gbasics}
\end{assu}

All graphs considered in this paper will satisfy assumption \ref{a::gbasics}. Countability is required for obvious reasons. We restrict our attention to rooted graphs so that we can clearly describe local properties (this could also be achieved using ordinary graphs and choosing an arbitrary vertex, however working with rooted graphs simplifies matters greatly). We need the graphs to be locally finite so that all finite vertex sets have finite neighborhoods within the graph. \tr{Most of my results currently hold only for bounded degree graphs rather than locally finite. For now I will write up the results as if I have already extended everything, but I need to keep an eye out for this assumption when pulling results from the main paper.}

\ind \tr{Connectedness is not actually necessary for my results. For well-posedness, it suffices to prove that the process is well-defined on all components (reducing to the connected case). Local convergence automatically discounts everything except for the connected component on which the root appears, so we can assume everything is connected without loss of generality. The conditional independence property holds on the whole graph if it holds on each component (by independence of the components). The local approximation would require some tedious graph theoretic arguments, but we can essentially ignore all components that do not contain a vertex from the admissible set. I suspect there's some simple way to consider each separate component of the admissible set separately, but I would have to think about it some more. I include the assumption of connectedness because I don't want to get bogged down in arguments about connected components.}

\ind Next, we need some general assumptions under which the process \(\Xf\) is well-defined.

\begin{assu}
\(G\) satisfies assumption \ref{a::gbasics}. \(\Xf\gind{G}\) satisfies equation \eqref{p::Xf}, and 
\begin{enumerate}
\item 

\begin{equation}
\ex{\sup_v |\Xf\gind{G}\vind{v}\tme{0}|} < \infty
\label{a::bddstart}
\end{equation}

\item 

\begin{equation}
\sum_{i \in \sta}|i|\sup_{v \in V,t \in \mb{R}^+} \rate\gvpara{G}{v}\stpara{i}\tme{t} < \infty
\label{a::bddjmp}
\end{equation}
\end{enumerate}

Furthermore, \(\rate\gvpara{G}{v}\stpara{i}\tme{t}\) is \(\F\vpara{\cl{v}}\tpara{t-}\) measurable for all \(v\in V,i \in \sta, t \in \mb{R}^+\), \(\rate\gvpara{G}{v}\stpara{i}\tme{t}: \mb{R}^+ \ra \mb{R}^+\) is almost surely left-continuous, and almost surely continuous at all continuity points of \(\Xf\vpara{\cl{v}}\).

\skipLine

Note: for clarity, I may occasionally use the notation, \(\rate\gvpara{G}{v}\stpara{i}(\Xf\gind{G}\vind{\cl{v}}\tmi{[0,t)}) \defeq \rate\gvpara{G}{v}\stpara{i}\tme{t}\).

\label{a::pbasics}
\end{assu}

\tr{Assumption \ref{a::pbasics} is subject to change. I'm just hypothesizing these conditions at the moment.} These equations simply ensure that \(\Xf\gind{G}\) does not explode in finite time. Hopefully this is enough to ensure that \(\Xf\gind{G}\) is the unique solution to equation \eqref{p::Xf}.

\ind The local equations (see section \iffalse\ref{}\fi) are derived through the application of numerous symmetries in the network and process. The best way to characterize these symmetries is in terms of isomorphisms.

\begin{defn}
Given two graphs \(G\) and \(G'\), an isomorphism is a bijection \(\phi: V \ra V'\) that satisfies \((\phi(u),\phi(v)) \in E'\) if and only if \((u,v) \in E\).
\label{a::iso}
\end{defn}

This notion can be extended to rooted graphs in the following manner:

\begin{defn}
A rooted isomorphism between two rooted graphs \(G\) and \(G'\) is an isomorphism \(\phi\) such that \(\phi(\root) = \root'\).
\label{a::riso}
\end{defn}

Symmetries naturally arise when we start looking at isomorphisms from a graph \(G\) to itself:

\begin{defn}
For any graph \(G\), a self-isomorphism \(\phi: V \ra V\) is an isomorphism from \(G\) to itself. Note: if \(G\) is a rooted graph, it is possible that \(\phi(\root) \neq \root\).
\label{a:siso}
\end{defn}

Of course, the most important point is that the symmetry extend to \(\Xf\).

\begin{defn}
Let \((G,\Xf\gind{G})\) be a process satisfying assumption \ref{a::pbasics}. \(\phi: V \ra V\) is said to be a symmetry of \(\Xf\gind{G}\) if,

\begin{enumerate}
\item \(\phi\) is a self-isomorphism of \(G\).

\item 

\begin{equation}
\rate\gvpara{G}{\phi(v)}\stpara{i}\left(\Xf\gind{G}\vind{\phi(\cl{v})}\tmi{[0,t)}\right) = \rate\gvpara{G}{v}\stpara{i}\left(\Xf\gind{G}\vind{\cl{v}}\tmi{[0,t)}\right) \te{ for all } v \in V,i \in \sta, t \in \mb{R}^+.
\end{equation}
\end{enumerate}
\label{a:Xsim}
\end{defn}

This is called a symmetry of \(\Xf\) for a simple reason:

\begin{prop}
Let \((G,\Xf\gind{G})\) satisfy assumption \ref{a::pbasics}, and suppose \(\phi\) is a symmetry of \(\Xf\gind{G}\). Suppose also that \(\Xf\gind{G}\vind{\phi(V)}\tme{0} \deq \Xf\gind{G}\vind{V}\tme{0}\). Then,

\[\Xf\gind{G}\vind{V} \deq \Xf\gind{G}\vind{\phi(V)},\]

where \(\phi(V)\) is treated as a permutation of \(V\).
\label{a::simprop}
\end{prop}
\begin{proof}
This proof assumes that assumption \ref{a::pbasics} is enough to ensure that \(\Xf\gind{G}\) is the unique solution to equation \eqref{p::Xf}. In that case, use the symmetries to show that equation \eqref{p::Xf} is invariant in law with respect to application of \(\phi\). \tr{(Refer to some of my older papers for such a proof.)}
\end{proof}

Now we can characterize the types of symmetries necessary for the local equations to be asymptotically exact.

\begin{assu}
Let \((G,\Xf\gind{G})\) satisfy assumption \ref{a::pbasics}. \(G\) is said to be admissible if there exists a finite set \(A \subset V\) such that,

\begin{itemize}
\item There exists a finite partition \(\{B_i\}_{i=1}^\psize\) of \(A^c\).

\item \(\dneigh{B_i} \subseteq A\) for all \(i\).

\item Let \(C_i = B_i\cap\neigh{A}\). For each \(i\), there exists a symmetry, \(\phi_i\), such that \(\phi_i(C_i\cup \dneigh{B_i}) \subset A\), and \(\phi_i(B_i\setminus C_i)\cap A = \emptyset\). \tr{The last one may be unnecessary, but it greatly simplifies the casework.}

\item If we let \(A\indx{1} = A\cup \left(\bigcup_{i=1}^\psize C_i\right)\). Then \(A\indx{1}\) is also admissible with partition \(\{B\indx{1}_i\}_{i=1}^{\psize\indx{1}}\) and boundary nodes \(C\indx{1}_i = B\indx{1}_i\cap \neigh{A\indx{1}}\).

\item If \(C\indx{1}_{i'} \subseteq B_i\), then there exists a \(j\) so that \(\phi_i(C\indx{1}_{i'}) = C_j\). \tr{I think this is implied by the other conditions if \(A\) has a unique corresponding set of branches and boundary nodes.}

\item If \(\phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\) is nonempty, then \(\phi_j(C_j)\cap\dgneigh{G}{B_{j'}} = \emptyset\). \tr{I suspect this can be proven using the points above. Try to do so or find a simpler set of assumptions that satisfy this.}
\end{itemize}

The set \(A\) is called an admissible set. \(\{B_i\}_{i=1}^\psize\) will be referred to as the set of branches of \(A\). \(\psize\) is the branching number of \(A\). \(\{C_i\}_{i=1}^\psize\) will be called the boundary nodes of \(A\).

\ind \tr{Right now I'm just adding assumptions whenever I need them (after making sure load-balancing satisfies them).}
\label{a::admissible}
\end{assu}

The definition of an admissible set is designed ensure a high enough level of symmetry for the arguments in the main paper to hold in this case as well. \tr{Interestingly enough, if this assumption suffices to prove the local approximation, then we will be able to understand the dynamics of a typical class of particles even when such particles are split into heterogeneous classes so long as they are distributed with a high level of symmetry. This will be especially useful if we consider random graphs later.}

\subsection{Examples}
\label{e::not}

\begin{itemize}
\item Ising/Potts Model on the regular tree.

\item Ising/Potts Model on the lattice (a counterexample).

\item \(k\)-neighbor JSQ routing for queues.

\item Asymmetric Exclusion Process.

\item Neuronal Models on tree-like structures.
\end{itemize}

\section{Well-Posedness and Convergence}
\label{WP}

Well-posedness is simple.

\begin{thms}
If assumptions \ref{a::gbasics} and \ref{a::pbasics} hold, then equation \eqref{p::Xf} has a unique strong solution.
\label{WP::WP}
\end{thms}
\begin{proof}
\tr{TODO}
\end{proof}

Often, the network of interest is a large, finite network. To analyze such a network, we consider an approximation at infinity. To do this, we need some appropriate notions of convergence.

\begin{defn}
The \(k\)-truncation of a rooted graph \(G = (V,E,\root)\) is the graph \(G\trnc{k}=(V\trnc{k},E\trnc{k},\root)\) given by,

\[V\trnc{k} = \{v \in V: d_G(v,\root) \leq k\} \te{ and } E\trnc{k} = \{(u,v) \in E: u,v \in V\trnc{k}\}.\]
\label{WP::trunc}
\end{defn}

\begin{defn}
Let \(G\indx{n} = (V\indx{n},E\indx{n},\root\indx{n})\) be a sequence of rooted graphs. We say \(G\indx{n} \ra G = (V,E,\root)\) locally if for every \(k\in \mb{N}\), there exists an \(n_k \in \mb{N}\) such that for all \(n \geq n_k\), there exists a graph isomorphism \(\psi_{n,k}: V\indx{n}\trnc{k} \ra V\trnc{k}\), where \(V\indx{n}\trnc{k}\) is the \(k\)th truncation of \(V\indx{n}\) and \(V\trnc{k}\) is the \(k\)th truncation of \(V\).
\label{WP::locconv}
\end{defn}

\begin{defn}
Let \(G^n\) be a sequence of graphs converging locally to a graph \(G\) that satisfies assumption \ref{a::gbasics}. Let \(\Xf\indx{n}\) be a \(\sta^{V\indx{n}}\)-valued process. Let \(\Xf\) be a \(\sta^V\)-valued process. 

\ind For every \(k\in \mb{N}\), \(n \geq n_k\) and \(v \in V\trnc{k}\), let \(\Xf\indx{n,k}\vind{v} = \Xf\indx{n}\vind{\psi_{n,k}^{-1}(v)}\). Then \(\Xf^n\) converges locally weakly to \(\Xf\) if for every \(k \in \mb{N}\),

\[\Xf^{n,k} \os{n\ra\infty}{\Rightarrow} \Xf_{V_k}.\]
\label{WP::locweak}
\end{defn}

\begin{thms}
Let \(G\indx{n}\) be a sequence of rooted graphs converging locally to \(G\), which satisfies assumption \ref{a::gbasics}. Suppose \(\Xf\gind{G}\) satisfies assumption \ref{a::pbasics}. Then \(\Xf\gind{G\indx{n}} \ra \Xf\gind{G}\) locally weakly.
\label{WP::lblocweak}
\end{thms}
\begin{proof}
\tr{I should be calling this a conjecture for now.}
\end{proof}

\section{Conditional Independence}
\label{CI}

The results from the main paper are almost sufficient. I just need to extend them to the infinite state space case and to work with non-Markovian processes. Only the arguments of Lemma 4.3 from the main paper rely on the process having a finite state space and Markov structure, so I only have to redo that one.

\begin{thms}
Suppose \((G,\Xf\gind{G})\) satisfy assumptions \ref{a::gbasics} and \ref{a::pbasics}. Let \(U \subseteq V\) and let \(W = V\setminus \ov{\ov{U}}\). Let \(R = \dneigh{U}\) and suppose \(|R| < \infty\). Then for all \(t < \infty\),

\begin{equation}
\Xf\vind{U}\tmi{[0,t)}\perp \Xf\vind{W}\tmi{[0,t)}|\Xf\vind{R}\tmi{[0,t)}
\label{CI::CIeqn}
\end{equation}

\label{CI::CI}
\end{thms}
\begin{proof}
I've proved version of this theorem in the main paper with stronger assumptions (Theorem 3.1) (\(\Xf\gind{G}\) is assumed to be Feller, \(G\) is assumed to be of bounded degree instead of locally-finite and \(\sta\) is assumed to be finite instead of countable). However, I suspect that proving this will only require some modifications to Lemma 4.3 from the main paper.
\end{proof}
\section{Statement of the Local Approximation}
\label{Main}


\begin{thms}
Let \((G,\Xf)\) satisfy assumption \ref{a::admissible}. Let \(A\) be the admissible set and \(\{B_i\}\) the branches of \(A\). Let \(\inte{A} = \{v \in A: \neigh{v} \subseteq A\}\). Consider the following equations:

\begin{align}
\Xg\vind{v}\tme{t} &= 
\begin{cases}
\Xg\vind{v}\tme{0} + \int_{\sta} \int_{[0,t)\times (0,\infty)} i\mb{I}_{r\leq \rate\gvpara{A}{v}\stpara{i}(\Xg\vind{\cl{v}}\tmi{[0,s)})}\,\poiss\poissv{v}(dr,ds,di) & \te{ if } v \in \inte{A}\\
\Xg\vind{v}\tme{0} + \int_{\sta} \int_{[0,t)\times (0,\infty)} i\mb{I}_{r\leq \brate\gvpara{A}{v}\stpara{i}(\Xg\vind{\dneigh{B_j}}\tmi{[0,s)})}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in \neigh{B_j}
\end{cases}\label{Main::local}\\
\brate\gvpara{A}{v}\stpara{i}(x_{\dneigh{B_j}}[0,t)) &= \exmu{\Xg \sim \mu}{\rate\gvpara{A}{\phi_j(v)}\stpara{i}\left(\Xg\vind{A}\tmi{[0,t)}\right)\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,t)} = x\vind{\dneigh{B_j}}\tmi{[0,t)}} \te{ if } v \in \neigh{B_j}\label{Main::CI}\\
\mu &= \law(\Xg).\label{Main::fixed}
\end{align}

Equations \eqref{Main::local}, \eqref{Main::CI} and \eqref{Main::fixed} have a unique weak solution in law satisfying the results of theorem \ref{CI::CI}, \(\mu = \law(\Xf\vind{A})\). (We don't yet have a general proof of uniqueness, just that only one of the solutions satisfies the conditional independence property outlined in section \ref{CI}).
\label{Main::Main}
\end{thms}

\subsection{Proof of Existence}
\label{Ex::Main}

In this section, we prove that \(\law(\Xf\vind{A})\) is a weak solution to equations \eqref{Main::local}-\eqref{Main::fixed} in Theorem \ref{Main::Main}.

Just like in the regular tree case, the idea of the proof is to convert \(\Xf\) into a point process and use a well-known filtration result for point processes.

\ind In this section, we assume \((G,\Xf)\) satisfy assumption \ref{a::admissible}. Recall that \(\proj\vpara{\cdot}\tpara{\cdot}(\cdot)\) is the projection mapping (see section \ref{p::not}).

\begin{defn}
Let \(U\subseteq V\) and suppose \(\Xg\) is a \(\sta^U\)-valued c\`adl\`ag stochastic process adapted to its own natural filtration. Define the marked point process \(\pmap(\Xg)\) as a random measure on \((0,\infty) \times \sta^U\) defined by,

\[\pmap(\Xg)(\{(\rt,\mark)\}) = \begin{cases}
1 &\te{ if } \Xg\tme{\rt} - \Xg\tme{\rt-} = \mark\\
0 &\te{ otherwise}
\end{cases}.\]

Similarly, for \(W \subseteq U\), \(\pmap\vpara{W}(\Xg) = \pmap\left(\proj\vpara{W}(\Xg)\right)\). For any \(v\in U\), \(\pmap\vpara{v}(\Xg)\) is a random measure on \((0,\infty) \times \sta\) given by,

\[\pmap\vpara{v}(\Xg)(\{(\rt,\mark)\}) = \begin{cases}
1 &\te{ if } \Xg\vind{v}\tme{\rt} - \Xg\vind{v}\tme{\rt-} = \mark\\
0 &\te{ otherwise}
\end{cases},\]

and

\[\pmap\vpara{v}(\Xg)(\{(\rt,\mark): \Xg\vind{v}\tme{\rt} - \Xg\vind{v}\tme{\rt-} \neq \mark\}) = 0.\]

Finally, for any \(T\in (0,\infty)\), \(\pmap\tpara{T}(\Xg) = \pmap(\Xg)|_{\ms{B}\left((0,T]\times\sta^U\right)}\). \(\pmap\vpara{W}\tpara{T}(\Xg)\) and \(\pmap\vpara{v}\tpara{T}(\Xg)\) are defined in a similar fashion.
\label{Ex::pmap}
\end{defn}

\begin{assu}
Let \(G\) satisfy assumption \ref{a::gbasics}, however assumptions \ref{a::pbasics} and \ref{a::admissible} need not hold. Let \(A\) be any finite set, and define the set \(U\) such that \(A\subseteq U \subseteq V\). Let \(\Xg\) be an \(\sta^U\)-valued c\`adl\`ag stochastic process on \((0,\infty)\). For each \(v\in U\), \(\pmap\vpara{v}(\Xg)\) has an \(\Xg\vind{A}\)-predictable intensity, \(\ratee\vpara{v}\), and there exists a constant \(C < \infty\) such that \(\sup_{v\in U}\sup_{t\in \mb{R}^+}\sum_{i \in \sta} \ratee\vpara{v}(t,i) \leq C\). Furthermore, \(f\tpara{t}: \cad([0,t),\sta^{|A|})\times \sta\ra[0,C]\) is a sequence of mappings such that for all \(\Xh \in \cad([0,\infty),\sta^{|A|})\), if \(t\in (0,\infty)\) is a continuity point of \(\Xh\), then \(t\) is a continuity point of \(s \mapsto f\tpara{s}(\Xh\tmi{[0,s)},z)\) for all \(z \in \sta\). \tr{Maybe move this technical assumption about \(f\) into section \ref{a::not}.}
\label{Ex::Eassu}
\end{assu}


\begin{lem}
Let \(\rp\) be an \(\F\)-adapted marked point process with \(\F\)-predictable intensity \(\ratee\) with respect to the reference measure \(\Sm\) on its mark space. For all \(t \in [0,\infty)\), let \(\sigma(\rp_{t}) \subseteq \alt{\F}_{t}\subset \F_{t}\) define a subfiltration of \(\F\) containing the history of \(\rp\). If there exists an \(\ell\times \pr\)-almost sure left-continuous modification of \(\cratee(t,\mark) := \ex{\ratee(t,\mark)|\alt{\F}_{t-}}\) with respect to \(t\), then \(\cratee\) is the \(\alt{\F}\)-predictable intensity of \(\rp\). \tr{Make sure the lemma stated in the book works for infinite time.}
\label{Ex::filtering}
\end{lem}

\begin{proof}
This is Lemma 5.3 from the main paper.
\end{proof}

Now we need a simple method to know when the conditional expectation has a left-continuous modification. The following lemma, although a technical lemma, may be more broadly useful. It is also later applied in the proof of uniqueness.


\begin{lem}
Suppose Assumption \ref{Ex::Eassu} holds. Let \(\mm = \law(\Xg)\) and \(W\subseteq A \subseteq U\subseteq V\). Let \(W'\subseteq A\) be such that \(|W'| = |W|\), and suppose there is a natural association between elements of \(W'\) and \(W\). For any \(i \in \sta\), let

\[\ratee\vpara{v}\tpara{t}(i) \defeq \exmu{\Xh\sim \mm}{f_t(\Xh\tmi{[0,t)},i)|\Xh\vind{W'}\tmi{[0,t)} = \Xg\vind{W}\tmi{[0,t)}}.\]

Then \(\ratee\vpara{v}\tpara{t}(i)\) has an almost surely left-continuous modification on \([0,T)\) with respect to \(t\) for every \(v \in A\) and \(\ell\)-almost every \(i \in \sta\), where \(\ell\) is the counting measure on \(\sta\) (see section \ref{p::not}). Furthermore, \(\ratee\vpara{v}\tpara{t}(i)\) is a.s. continuous at all continuity points of \(\Xg\vind{W}\).
\label{Ex::leftmod}
\end{lem}
\begin{proof}
Lemma 5.4 of the main paper is extremely similar to this Lemma. I can go back and generalize that Lemma to apply to this situation later so that this becomes a direct application of lemma 5.4 of the main paper.
\end{proof}

\begin{proof}[Proof of Theorem \ref{Main::Main} Existence]

Let \((G,\Xf)\) be a process and graph satisfying assumption \ref{a::admissible}. Let \(\ev{v} \in \sta^V\) denote the standard basis vector of \(\sta^V\). That is, \(\ev{v}\vind{u} = \mb{I}_{u=v}\). By Theorem \ref{WP::WP}, \(\Xf\) is the unique solution to,

\[\Xf\tme{t} = \Xf\tme{0} + \sum_{v \in V}\ev{v}\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \rate\gvpara{G}{v}\stpara{i}\tme{s}}\,\poiss\poissv{v}(dr,ds,di).\]

Then,

\[\left(\proj\vpara{A}(\Xf)\right)\tme{t} = \left(\proj\vpara{A}(\Xf)\right)\tme{0} + \sum_{v\in A}\ev{v}\int_\sta\int_{(0,t]\times (0,\infty)} i\mb{I}_{r \leq \rate\gvpara{G}{v}\stpara{i}\tme{s}}\,\poiss\poissv(dr,ds,di).\]

By definition, \(\pmap\left(\proj\vpara{A}(\Xf)\right) = \pmap\vpara{A}(\Xf)\). Let \(\rp = \pmap\vpara{A}(\Xf)\). By \cite[Exercise 14.7.1]{DalVer08}, \(\rp\) has \(\Xf\)-predictable intensity \(\ratee\) given by,

\[\ratee(\rt,\mark) = \sum_{v \in A} \sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}} \rate\gvpara{G}{v}\stpara{i}\tme{\rt}.\]

However, for \(v \in A\setminus \inte{A}\), \(\rate\gvpara{G}{v}\stpara{i}\tme{\rt}\) is not \(\Xf\vind{A}\)-measurable. Furthermore, for \(v \in \inte{A}\), notice that \(\rate\gvpara{G}{v}\stpara{i}\tme{\rt} = \rate\gvpara{A}{v}\stpara{i}\tme{\rt}\) by assumption \ref{a::pbasics}. So, let's propose an alternate rate given by,

\begin{equation}
\alt{\ratee}(\rt,\mark) = \sum_{v \in \inte{A}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}}\rate\gvpara{A}{v}\stpara{i}\tme{\rt} + \sum_{v \in A\setminus \inte{A}}\sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}}\ex{\rate\gvpara{G}{v}\stpara{i}\tme{\rt}\middle|\F\vpara{A}\tpara{\rt-}}.
\label{Ex::tempfiltrate}
\end{equation}

Notice that by lemma \ref{Ex::filtering}, if \(\alt{\ratee}\) has a \(\Sm\times \pr\)-a.s. left-continuous modification with respect to time, then it is the \(\F\vpara{A}\)-predictable rate of \(\rp\). For all \(i\in\sta\) and \(v \in A\), \(\rate\gvpara{G}{v}\stpara{i}\tme{\cdot}\) is almost surely left-continuous and bounded. Thus, it suffices to prove that \(\ex{\rate\gvpara{G}{v}\stpara{i}(\rt)\middle|\F\vpara{A}\tpara{\rt-}}\) also has a left continuous modification for all \(i\in \sta\) and \(v \in A\setminus\inte{A}\).

\ind Fix some \(v \in A\setminus \inte{A}\). By assumption \ref{a::admissible}, there exists a unique \(j\) such that \(v \in \neigh{B_j}\). Recall that \(C_j = \neigh{A}\cap B_j\), and there exists a symmetry of \(\Xf\), \(\phi_j\) such that \(\phi_j(C_j\cup\dneigh{B_j}) \subseteq A\). By proposition \ref{a::simprop}, \(\Xf\vind{V} \deq \Xf\vind{\phi_j(V)}\). It should be clear that \(\cl{v} \subseteq C_j\cup\dneigh{B_j}\).

\ind Recalling that \(\m = \law(\Xf)\) and applying Theorem \ref{Main::CI} (we may consider \(\rate\gvpara{G}{v}\stpara{i}\tme{\rt}\) as a \(\F\vpara{C_j\cup\dneigh{B_j}}\tpara{\rt-}\)-measurable random variable and apply Lemma C.1 (e) from the main paper),

\begin{align*}
\exmu{\m}{\rate\gvpara{G}{v}\stpara{i}\tme{\rt}\middle|\F\vpara{A}\tpara{\rt-}} &=\exmu{\m}{\rate\gvpara{G}{v}\stpara{i}\left(\Xf\vind{\cl{v}}\tmi{[0,\rt)}\right)\middle|\F\vpara{A}\tpara{\rt-}}\\
&\os{\te{thm \ref{Main::CI}}}{=} \exmu{\m}{\rate\gvpara{G}{v}\stpara{i}\left(\Xf\vind{\cl{v}}\tmi{[0,\rt)}\right)\middle|\F\vpara{\dneigh{B_j}}\tpara{\rt-}}\\
&=\exmu{\Xg\sim \m}{\rate\gvpara{G}{v}\stpara{i}\left(\Xg\vind{\cl{v}}\tmi{[0,\rt)}\right)\middle|\Xg\vind{\dneigh{B_j}}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}\\
&\os{\te{prop \ref{a::simprop},assm \ref{a::pbasics}}}{=} \exmu{\Xg\sim \m}{\rate\gvpara{G}{\phi_j(v)}\stpara{i}\left(\Xg\vind{\phi_j(\cl{v})}\tmi{[0,\rt)}\right)\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}\\
&\os{\phi_j(v) \in \inte{A}}{=} \exmu{\Xg\sim \m}{\rate\gvpara{A}{\phi_j(v)}\stpara{i}\left(\Xg\vind{\phi_j(\cl{v})}\tmi{[0,\rt)}\right)\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}\\
\end{align*}

Notice that this satisfies assumption \ref{Ex::Eassu} with \(f_t = \rate\gvpara{A}{\phi_j(v)}\stpara{i}\), \(U = V\), \(A\) as the admissible set, the intensities satisfy the requisite bound by assumption \ref{a::pbasics}. Here \(W = \dneigh{B_j}\) and \(W' = \phi_j(\dneigh{B_j})\). Since they are related by a symmetry, \(|W'| = |W|\). Thus, by lemma \ref{Ex::leftmod}, \(\exmu{\m}{\rate\gvpara{G}{v}\stpara{i}\tme{\rt}\middle|\F\vpara{A}\tpara{\rt-}}\) has a left-continuous modification. Then \(\alt{\ratee}\) must also have a left-continuous modification, and 

\[\alt{\ratee}(\rt,\mark) = \sum_{v \in \inte{A}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}}\rate\gvpara{A}{v}\stpara{i}\tme{\rt} + \sum_j\sum_{v \in B_j}\sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}}\exmu{\Xg\sim \m}{\rate\gvpara{A}{\phi_j(v)}\stpara{i}\left(\Xg\vind{\phi_j(\cl{v})}\tmi{[0,\rt)}\right)\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,\rt)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,\rt)}}.\]

Once again, by \cite[Exercise 14.7.1]{DalVer08}, the process \(\pmap^{-1}(\rp) \deq \proj\vpara{A}(\Xf)\), and can be written as a solution to the equations,

\[\Xg\vind{v}\tme{t} = \Xg\vind{v}\tme{0} + \begin{cases}
\int_\sta\int_{(0,t]\times (0,\infty)} \rate\gvpara{A}{v}\stpara{i}\tme{s}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in \inte{A}\\
\int_\sta\int_{(0,t]\times (0,\infty)} \brate\gvpara{A}{v}\stpara{i}\tme{s}\,\poiss\poissv{v}(dr,ds,di) &\te{ if } v \in A\setminus\inte{A}
\end{cases},\]

where

\[\brate\gvpara{A}{v}\stpara{i}\tme{t} = \exmu{\Xg\sim \m}{\rate\gvpara{G}{\phi_j(v)}\stpara{i}\left(\Xg\vind{\phi_j(\cl{v})}\tmi{[0,t)}\right)\middle|\Xg\vind{\phi_j(\dneigh{B_j})}\tmi{[0,t)} = \Xf\vind{\dneigh{B_j}}\tmi{[0,t)}}\te{ if } v \in \neigh{B_j}.\]

\end{proof}

\section{Proof of Uniqueness}
\label{Uq}

Let \((\mm,\Xg)\) be a solution to the local equations (\eqref{Main::local}-\eqref{Main::fixed}). Assume that for every \(U,U' \subseteq A\) such that \(\{U,U',\dgneigh{A}{U}\}\) is a partition of \(A\) and \(t \in [0,\infty)\),

\[\Xg\vind{U}\tmi{[0,t)} \perp \Xg\vind{U'}\tmi{[0,t)} |\Xg\vind{\dgneigh{A}{U}}\tmi{[0,t)}.\]

Our approach to this proof will be to construct a measure \(\mm\vpara{V} \in \pmsr(\sta^V)\) such that \(\proj\psf\vpara{A}(\mm\vpara{V}) = \mm\). Then we will show that \(\mm\vpara{V} = \m\). 

\ind \tr{Insert explanation here. The gist is we need to understand the conditional distribution of each boundary set of \(A\) given it's double neighborhood inside \(A\). We can do this by studying the same conditional distribution in a symmetry that takes the set inside \(A\). To do that, we start by computing the marginals of the double neighborhood, and the whole set under the application of symmetry.}

\begin{lem}
For all \(j \in \{1,\dots,\psize\}\), \(\proj\psf\vpara{\phi_j(\dgneigh{G}{B_j})}(\mm)\) is equal in distribution to the unique strong solution to the following equation:

\begin{equation}
\Xh\vind{v}\tme{t} = \Xh\vind{v}\tme{0} + \begin{cases}
\int_\sta\int_{(0,t]\times (0,\infty)} \mb{I}_{r \leq \brate\gvpara{A}{v}\stpara{i}(s)}\,\poiss\poissv{v}(dr,ds,di)&\te{ if } v \in \phi_j(\dgneigh{G}{B_j})\cap \inte{A}\\
\int_\sta\int_{(0,t]\times (0,\infty)} \mb{I}_{r \leq \bcrate\gvpara{A}{v}\stpara{i}(s)}\,\poiss\poissv{v}(dr,ds,di)&\te{ if } v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}
\end{cases}
\label{Uq::marg1eqn}
\end{equation}

where \(j' \in \{1,\dots,\psize\}\) is not necessarily distinct from \(j\), and

\begin{align}
\bgrate\gvjpara{A}{v}{B_j}\stpara{i}(t) &\defeq \ex{\rate\gvpara{A}{v}\stpara{i}\left(\Xh\vind{\cl{v}}\tmi{[0,t)}\right)\middle|\Xh\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,t)}} \te{ if } v \in  \phi_j(\dgneigh{G}{B_j})\cap \inte{A} \label{Uq::brrt}\\
\bcrate\gvjpara{A}{v}{B_j}\stpara{i}(t) &\defeq \ex{\brate\gvpara{A}{v}\stpara{i}\left(\Xh\vind{\dgneigh{G}{B_{j'}}}\tmi{[0,t)}\right)\middle| \Xh\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,t)}} \te{ if } v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\label{Uq::brcdrt}
\end{align}
\label{Uq::marg}
\end{lem}
\begin{proof}

Let \(\rp = \pmap(\Xg)\) where \(\Xg \sim \mm\). By a direct application of \cite[Exercise 14.7.1]{DalVer08}, \(\rp\vind{\phi_j(\dgneigh{G}{B_j})}\) has \(\Xg\)-intensity \(\ratee\) given by,

\begin{equation}
\ratee(\rt,\mark) = \sum_{v \in\phi_j(\dgneigh{G}{B_j})\cap\inte{A}} \sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}} \rate\gvpara{A}{v}\stpara{i}(\Xg\vind{\cl{v}}\tmi{[0,\rt)}) + \sum_{j = 1}^\psize\sum_{v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_j}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}} \brate\gvpara{A}{v}\stpara{i}(\Xg\vind{\dgneigh{G}{B_j}}\tmi{[0,\rt)}).
\label{Uq::Xg-int}
\end{equation}

Consider the following candidate for the \(\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\)-intensity of \(\rp\), 

\[\cratee(\rt,\mark) \defeq \exmu{\Xg \sim \mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}}.\]

By lemma \ref{Ex::filtering}, it \(\cratee\) is the intensity if it has a \(\pr\times\Sm\)-a.s. left-continuous modification with respect to \(\rt\). Since \(\ratee\) is a countable sum of elements of which finitely many (one) are nonzero for any given argument \((\rt,\mark)\), it suffices to prove that the conditional expectation of each element of equation \eqref{Uq::Xg-int} is also left continuous. This leaves us with two cases.

\begin{description}
\item[Case 1: ] \(v \in \phi_j(\dgneigh{G}{B_j})\cap\inte{A}\).

In this case, fix \(i,v\) and \(\mark = i\ev{v}\).

\begin{align*}
\cratee(\rt,\mark) &= \exmu{\Xg\sim\mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}} = \exmu{\Xg\sim\mm}{\rate\gvpara{A}{v}\stpara{i}(\Xg\vind{\cl{v}}\tmi{[0,\rt)})\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}}.
\end{align*}

Looking back at assumption \ref{Ex::Eassu}, our graph \(G\) is assumed to satisfy assumption \ref{a::gbasics}. Let \(A\) from the assumption be the same as the admissible set, \(A\), from this lemma. Let \(U = A\). \(\Xg\) from the assumption is precisely \(\rp\). \(\ratee\) satisfies the conditions of the intensity by assumption \ref{a::pbasics}. \(f_t\) from the assumption is just \(\rate\gvpara{A}{v}\stpara{i}(\cdot)\), which satisfies the continuity property by \ref{a::pbasics}. So, the conditions of assumption \ref{Ex::Eassu} hold in this case. Furthermore, from the conditions of lemma \ref{Ex::leftmod}, let \(W = W' = \phi_j(\dgneigh{G}{B_j})\). Then by lemma \ref{Ex::leftmod}, \(\cratee(\rt,\mark)\) has a left continuous modification wrt \(\rt\).

\skipLine

\item[Case 2: ] \(v \in \phi_j(\dgneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\) where \(j,j'\) are not necessarily distinct.

In this case, fix \(i,v\) and \(\mark = i\ev{v}\).

\begin{align*}
\cratee(\rt,\mark) &= \exmu{\Xg\sim\mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}} = \exmu{\Xg\sim\mm}{\brate\gvpara{A}{v}\stpara{i}(\Xg\vind{\dgneigh{G}{B_{j'}}}\tmi{[0,\rt)})\middle|\Xg\vind{\phi_j(\dgneigh{G}{B_j})}\tmi{[0,\rt)}}.
\end{align*}

Looking back at assumption \ref{Ex::Eassu}, our graph \(G\) is assumed to satisfy assumption \ref{a::gbasics}. Let \(A\) from the assumption be the same as the admissible set, \(A\), from this lemma. Let \(U = A\). \(\Xg\) from the assumption is precisely \(\rp\). \(\ratee\) satisfies the conditions of the intensity by assumption \ref{a::pbasics}. \(f_t\) from the assumption is just \(\rate\gvpara{A}{v}\stpara{i}(\cdot)\), which satisfies the continuity property by \ref{a::pbasics}. So, the conditions of assumption \ref{Ex::Eassu} hold in this case. Furthermore, from the conditions of lemma \ref{Ex::leftmod}, let \(W = W' = \phi_j(\dgneigh{G}{B_j})\). Then by lemma \ref{Ex::leftmod}, \(\cratee(\rt,\mark)\) has a left continuous modification wrt \(\rt\).
\end{description}
\end{proof}

Now we compute the marginal distribution of \(C_j\cap\dgneigh{G}{B_j}\) under symmetry. 
%However, before doing that, we need a graph theoretic result:
%
%\begin{lem}
%For all \(j \in \{1,\dots,\psize\}\), \(\phi_j(C_j)\cap \inte{A} = \emptyset\).
%\label{Uq::symbdry}
%\end{lem}
%\begin{proof}
%Fix \(j\). By assumption \ref{a::admissible}, there exists a \(j'\) such that \(\phi_j(C_{j'}\indx{1}) = C_j\) for some \(C_{j'}\indx{1}\) such that \(C_{j'}\indx{1} \subseteq B_j\). In fact, \(C_{j'}\indx{1} \subseteq \gneigh{C_j}\).
%
%\ind Then, since \(\phi_j(C_{j'}\indx{1}) = C_j\), we can conclude that \(\gneigh{G}{\phi_j(C_j)} \supseteq \phi_j 
%\end{proof}

\begin{lem}
For all \(j \in \{1,\dots,\psize\}\), \(\proj\psf\vpara{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}(\mm)\) is equal in distribution to the unique strong solution to the following equation:

\begin{equation}
\Xh\vind{v}\tme{t} = \Xh\vind{v}\tme{0} + \begin{cases}
\int_\sta\int_{(0,t]\times(0,\infty)} \mb{I}_{r \leq \brate\gvpara{A}{v}\stpara{i}\tme{s}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(C_j)\\
\int_\sta\int_{(0,t]\times(0,\infty)} \mb{I}_{r \leq \rate\gvpara{A}{v}\stpara{i}\tme{s}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(\gneigh{G}{B_j})\\
\int_\sta\int_{(0,t]\times(0,\infty)} \mb{I}_{r \leq \bgrate\gvjpara{A}{v}{B_j}\stpara{i}\tme{s}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\inte{A}\\
\int_\sta\int_{(0,t]\times(0,\infty)} \mb{I}_{r \leq \bcrate\gvjpara{A}{v}{B_j}\stpara{i}\tme{s}}\,\poiss\poissv{v}(dr,ds,di).\te{ if } v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\gneigh{G}{B_{j'}}\\
\end{cases}
\label{Uq::marg2eqn}
\end{equation}

where \(\rate,\brate,\bgrate\) and \(\bcrate\) are as defined in lemma \ref{Uq::marg}, theorem \ref{Main::Main}, assumption \ref{a::pbasics} and assumption \ref{a::admissible}.
\label{Uq::marg2}
\end{lem}
\begin{proof}
The proof is similar to the proof of lemma \ref{Uq::marg}. Only there are more cases. Once again, let \(\Xg \sim \mm\), \(\rp = \pmap(\Xg)\). Then by \cite[Exercise 14.7.1]{DalVer08}, \(\rp\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\) has \(\Xg\)-intensity \(\ratee\) given by,

\begin{equation}
\ratee(\rt,\mark) = \sum_{v \in\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)\cap\inte{A}} \sum_{i \in \sta} \mb{I}_{\mark = i\ev{v}} \rate\gvpara{A}{v}\stpara{i}(\Xg\vind{\cl{v}}\tmi{[0,\rt)}) + \sum_{j = 1}^\psize\sum_{v \in \phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)\cap\gneigh{G}{B_j}}\sum_{i\in \sta} \mb{I}_{\mark = i\ev{v}} \brate\gvpara{A}{v}\stpara{i}(\Xg\vind{\dgneigh{G}{B_j}}\tmi{[0,\rt)}).
\label{Uq::Xg-int2}
\end{equation}

Consider the following candidate for the \(\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\)-intensity of \(\rp\), 

\[\cratee(\rt,\mark) \defeq \exmu{\Xg \sim \mm}{\ratee(\rt,\mark)\middle|\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}.\]

By lemma \ref{Ex::filtering}, \(\cratee\) is the intensity if it has a \(\pr\times\Sm\)-a.s. left-continuous modification with respect to \(\rt\). Since \(\ratee\) is a countable sum of elements of which finitely many (one) are nonzero for any given argument \((\rt,\mark)\), it suffices to prove that the conditional expectation of each element of equation \eqref{Uq::Xg-int} is also left continuous. 

\ind \tr{move this new argument to lemma \ref{Uq::marg}.}

\ind Notice that \(G\) satisfies assumption \ref{a::gbasics}. Let \(A\) from assumption \ref{Ex::Eassu} be the same as our admissible set. Let \(U = A\). Let \(\Xg\) from assumption \ref{Ex::Eassu} be the same as \(\Xg\) in this context. The intensity satisfies the boundedness condition as a consequence of assumption \ref{a::pbasics}. For fixed \(\kappa\), \(\ratee\) can be considered a function satisfying the conditions of \(f_t\) from assumption \ref{Ex::Eassu}. Finally, in the conditions for lemma \ref{Ex::leftmod}, we can let \(W = W' = \phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)\). Thus, by lemma \ref{Ex::leftmod}, \(\cratee\) has a left-continuous modification.

\ind Now we evaluate \(\cratee\) for different \(\kappa\). Suppose \(\kappa = i\ev{v}\), where \(i \in \sta\) and \(v\in A\) are fixed.

\begin{description}
\item[Case 1: ] \(v \in \phi_j(C_j)\).

By assumption \ref{a::admissible}, \(\cl{v} \cap A \subseteq \phi_j(C_j\cup \gneigh{G}{B_j})\), and \(v \in A\setminus\inte{A}\). Thus, \(\cratee(\rt,\mark) = \brate\gvpara{A}{v}\stpara{i}(\rt)\).

\item[Case 2: ] \(v\in \phi_j(\gneigh{G}{B_j})\). 

Because \(\phi_j\) is a self-isomorphism, \(\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right) \subseteq A\) and \(\cl{v} \subseteq C_j\cup\dgneigh{G}{B_j}\), we can conclude that \(v \in \inte{A}\). Since \(\rate\gvpara{A}{v}\stpara{i}(\rt)\) is \(\F\vpara{C_j\cup\dgneigh{G}{B_j}}\tpara{\rt-}\)-measurable, we can conclude that \(\cratee(\rt,\mark) = \rate\gvpara{A}{v}\stpara{i}(\rt)\).

\item[Case 3: ] \(v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap\inte{A}\).

Because \(\Xg\sim\mm\), \(\ratee(\rt,\mark) = \rate\gvpara{A}{v}\stpara{i}(\rt)\) which is \(\F\vpara{\cl{v}}\tpara{\rt-}\)-measurable. We can consider this to be a measurable function of \(\Xg\vind{A\setminus\phi_j(C_j)}\tmi{[0,\rt)}\). By applying lemma C.1 (e) of the main paper, we get

\begin{align*}
\cratee(\rt,\mark) &= \ex{\rate\gvpara{A}{v}\stpara{i}(\rt)\middle|\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \ex{\rate\gvpara{A}{v}\stpara{i}(\rt)\middle|\Xg\vind{\phi_j\left(\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \bgrate\gvjpara{A}{v}{B_j}\stpara{i}\tme{\rt}.
\end{align*}

\item[Case 4: ] \(v \in \phi_j(\dgneigh{G}{B_j}\setminus\gneigh{G}{B_j})\cap \gneigh{G}{B_{j'}}\) for some \(j'\) not necessarily distinct from \(j\).

First, by assumption \ref{a::admissible}, \(\phi_j(C_j)\cap\dgneigh{G}{B_{j'}}= \emptyset\). Because \(\Xg\sim\mm\), \(\ratee(\rt,\mark) = \brate\gvpara{A}{v}\stpara{i}(\rt)\) which is \(\F\vpara{\dgneigh{G}{B_{j'}}}\tpara{\rt-}\)-measurable. We can consider this to be a measurable function of \(\Xg\vind{A\setminus\phi_j(C_j)}\tmi{[0,\rt)}\). By applying lemma C.1 (e) of the main paper, we get

\begin{align*}
\cratee(\rt,\mark) &= \ex{\brate\gvpara{A}{v}\stpara{i}(\rt)\middle|\Xg\vind{\phi_j\left(C_j\cup\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \ex{\brate\gvpara{A}{v}\stpara{i}(\rt)\middle|\Xg\vind{\phi_j\left(\dgneigh{G}{B_j}\right)}\tmi{[0,\rt)}}\\
&= \bcrate\gvjpara{A}{v}{B_j}\stpara{i}\tme{\rt}.
\end{align*}
\end{description}

The lemma follows by direct application of \cite[Exercise 14.7.1]{DalVer08}.
\end{proof}

As we extend \(\mm\) to larger processes, it's easiest to look at these larger processes in terms of their density with respect to a standard process.

\begin{defn}
Let \(\poiss\) be a Poisson random measure on \(\sta\times\mb{R}^2\) with intensity \(\Sm\times\leb\). Define \(\Xh\) by,

\[\Xh\vind{v}\tme{t} = \Xh\vind{v}\tme{0} + \int_{\sta}\int_{(0,t]\times (0,1]}\,\poiss(dr,ds,di).\]

Let \(\mmm = \law(\Xh)\). Suppose \(\mm\vpara{v}\tpara{0}\ll\mmm\tpara{0}\) for all \(v\in A\). Let \(\{\mmm\vind{v}:v\in V\}\) be the distributions of a sequence of i.i.d. copies of the measure \(\mmm\). For any \(U\subseteq V\), let 

\[\mmm\vpara{U} = \otimes_{v\in U} \mm\vpara{v}.\]

Finally, for any \(T < \infty\) and \(t\in [0,T)\), let \(\mm\vpara{U}\tpara{t}\) be the restriction of \(\mm\vpara{U}\) to c\`adl\`ag processes defined on \([0,T)\) (see section \ref{p::not}).
\label{Uq::eta}
\end{defn}

We now have to describe how to extend the graph \(G\vind{A}\).

\begin{defn}
As in assumption \ref{a::admissible}, let \(A\indx{1} = A\cup\left(\bigcup_{i=1}^\Sm C_i\right)\). By assumption \ref{a::admissible}, we can find branches of \(A\indx{1}\), \(\{B_i\indx{1}\}_{i=1}^{\Sm\indx{1}}\). Let \(C_i\indx{1} = B_i\indx{1}\cap\gneigh{G}{A\indx{1}}\). Finally, for all \(i = 1,\dots,\Sm\indx{1}\), let \(\phi_i\indx{1}\) be a symmetry of \(\Xf\) mapping \(C_i\indx{1}\cup \dgneigh{G}{B\indx{1}_i}\) to a subset of \(A\). We can assume without loss of generality that \(\phi_i\indx{1}(C_i\indx{1}\cup \dgneigh{G}{B\indx{1}_i}) = \phi_{j\indx{1}_i}(C_{j\indx{1}_i}\cup\dgneigh{G}{B_{j\indx{1}_i}})\) for some \(j\indx{1}_i \in \{1,\dots,\Sm\}\).

\ind In general, let \(A\indx{k+1} = A\indx{k} \cup \left(\bigcup_{i=1}^{\Sm\indx{k}} C_i\indx{k}\right)\). Again, by assumption \ref{a::admissible}, there exist branches of \(A\indx{k+1}\), \(\{B_i\indx{k+1}\}_{i=1}^{\Sm\indx{k+1}}\). Let \(C_i\indx{k+1} = B_i\indx{k+1}\cap \gneigh{G}{A\indx{k+1}}\). Finally, for all \(i=1,\dots,\Sm\indx{k+1}\), \(\phi_i\indx{k+1}\) is the symmetry of \(\Xf\) mapping \(C_i\indx{k+1}\cup\dgneigh{G}{B_i\indx{k+1}}\) to \(\phi_{j\indx{k+1}_i}(C_{j\indx{k+1}_i}\cup\dneigh{G}{B_{j\indx{k+1}_i}})\) for some \(j\indx{k+1}_i \in \{1,\dots,\Sm\}\).
\end{defn}

\begin{lem}
hi
\end{lem}



\newpage
\bibliographystyle{plain}
\bibliography{weekly_refs}
\end{document}
